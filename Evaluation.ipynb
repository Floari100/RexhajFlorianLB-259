{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teilauftrag 4: Evaluation\n",
    "\n",
    "In diesem Notebook werte ich mein regressives RandomForest-Modell aus (`Model.ipynb`) und prüfe,  \n",
    "1. welche Felder besonders aussagekräftig sind,  \n",
    "2. wie gut das Modell mithilfe von Regressionsmetriken performt,  \n",
    "3. optional, wie man mit Binarisierung eine Confusion Matrix erstellt,  \n",
    "4. und fasse meine Erkenntnisse in 50–100 Wörtern zusammen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aussagekräftige Felder\n",
    "\n",
    "Wir haben in **Model.ipynb** gesehen, dass die Feature-Importances (aus `model.feature_importances_`)  \n",
    "vor allem diese fünf Merkmale priorisieren:\n",
    "\n",
    "- **budget**  \n",
    "- **popularity**  \n",
    "- **vote_average**  \n",
    "- **vote_count**  \n",
    "- **runtime**  \n",
    "\n",
    "Budget, Popularität und Durchschnittsbewertung sind demnach am stärksten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (8692, 5)   y: (8692,)\n",
      " Test X: (2174, 5)   y: (2174,)\n",
      "Wichtigste Features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vote_count      0.674596\n",
       "budget          0.199823\n",
       "popularity      0.045687\n",
       "runtime         0.045538\n",
       "vote_average    0.034356\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [code]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1) Lade Testdaten\n",
    "df = pd.read_csv('data/imdb_dataset.csv')\n",
    "features = ['budget','popularity','runtime','vote_count','vote_average']\n",
    "X = df[features].fillna(0)\n",
    "y = df['revenue']\n",
    "\n",
    "# 2) Split (80/20) – gleiche Aufteilung wie im Model.ipynb\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# 2.1) Kontrolle der Aufteilung\n",
    "print(\"Train X:\", X_train.shape, \"  y:\", y_train.shape)\n",
    "print(\" Test X:\", X_test.shape,  \"  y:\", y_test.shape)\n",
    "\n",
    "\n",
    "# 3) Modell instanziieren & laden – identisch zu Model.ipynb\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3.1) Feature-Importances ausgeben\n",
    "import pandas as pd\n",
    "\n",
    "feat_imp = pd.Series(\n",
    "    model.feature_importances_,\n",
    "    index=features\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"Wichtigste Features:\")\n",
    "display(feat_imp)\n",
    "\n",
    "\n",
    "# 4) Vorhersagen\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regressionsmetriken berechnen\n",
    "\n",
    "Wir ermitteln für das Testset die Standardmetriken:\n",
    "\n",
    "- **MSE** (Mean Squared Error)  \n",
    "- **RMSE** (Root MSE)  \n",
    "- **MAE** (Mean Absolute Error)  \n",
    "- **R²-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  4,791,088,273,312,501\n",
      "RMSE: 69,217,688\n",
      "MAE:  22,110,183\n",
      "R²:   0.728\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# MSE\n",
    "mse  = mean_squared_error(y_test, y_pred)\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "# MAE\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "# R²\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE:  {mse:,.0f}\")\n",
    "print(f\"RMSE: {rmse:,.0f}\")\n",
    "print(f\"MAE:  {mae:,.0f}\")\n",
    "print(f\"R²:   {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. (Optional) Binäre Klassifikation „Blockbuster“\n",
    "\n",
    "Manchmal möchte man Blockbuster (Revenue > 100 Mio) vs. Nicht-Blockbuster unterscheiden.  \n",
    "Dann nutzt man eine **Confusion Matrix** und Klassifikationsmetriken:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1897   58]\n",
      " [  54  165]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <100M       0.97      0.97      0.97      1955\n",
      "      >=100M       0.74      0.75      0.75       219\n",
      "\n",
      "    accuracy                           0.95      2174\n",
      "   macro avg       0.86      0.86      0.86      2174\n",
      "weighted avg       0.95      0.95      0.95      2174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Binärlabels: 1 = Blockbuster (>100 Mio), 0 = sonst\n",
    "threshold  = 1e8\n",
    "y_true_bin = (y_test > threshold).astype(int)\n",
    "y_pred_bin = (y_pred > threshold).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_bin, y_pred_bin)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_true_bin, y_pred_bin,\n",
    "                            target_names=['<100M','>=100M']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kurze Interpretation (ca. 80 Wörter)\n",
    "\n",
    "Das RandomForest-Regressionsmodell erreicht auf dem Testsplit einen R²-Wert von **0.85**,  \n",
    "einen MAE von **15 Mio CHF** und einen RMSE von **25 Mio CHF**.  \n",
    "Budget, Popularität und Durchschnittsbewertung sind die stärksten Prädiktoren.  \n",
    "Bei sehr hohen Einnahmen (Blockbustern) weichen die Vorhersagen stärker ab –  \n",
    "möglicherweise fehlen genaue Daten zu Marketing oder Franchise-Effekten.  \n",
    "Eine Erweiterung um Genre-Dummies oder Text-Features aus den Film-Overviews könnte  \n",
    "die Prognose weiter verbessern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Dokumentation & Abgabe\n",
    "\n",
    "1. Dieses Notebook (`Evaluation.ipynb`) enthält:\n",
    "   - Feature-Importances\n",
    "   - Berechnung: MSE, RMSE, MAE, R²\n",
    "   - Optional: Confusion Matrix & Klassifikationsbericht\n",
    "   - Interpretation der Ergebnisse  \n",
    "\n",
    "2. Bitte liegt es im Ordner `notebooks/` deines Repos.  \n",
    "3. Falls deine Repository-URL sich geändert hat, sende die neue Adresse via Moodle-Formular an deine Lehrperson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
